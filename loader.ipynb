{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Khoawawa/Art-Detective/blob/main/loader.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Khoawawa/Art-Detective.git"
      ],
      "metadata": {
        "id": "394iUdvSWlFn",
        "outputId": "1d290edc-6c19-4645-ab53-aae3bb9e403d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'Art-Detective' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d alessandrasala79/ai-vs-human-generated-dataset -p /content/dataset --unzip"
      ],
      "metadata": {
        "id": "Q4_O2cPcUc05",
        "outputId": "e969754b-e76c-419c-c82f-acdb66937c2e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/alessandrasala79/ai-vs-human-generated-dataset\n",
            "License(s): apache-2.0\n",
            "Downloading ai-vs-human-generated-dataset.zip to /content/dataset\n",
            "... resuming from 556986368 bytes (9918403214 bytes left) ...\n",
            "  9% 893M/9.76G [00:02<01:25, 111MB/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "from IPython.display import display\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "rHZ8d4ZUn07w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = '/content/dataset'\n",
        "TRAIN_CSV = path + '/train.csv'\n",
        "TEST_CSV = path + '/test.csv'\n",
        "DATA_DIR = path"
      ],
      "metadata": {
        "id": "JZpD4RV9qXNz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.read_csv(TRAIN_CSV)\n",
        "train_df = train_df[['file_name','label']]\n",
        "train_df.columns = ['id','label']\n",
        "train_df.head()"
      ],
      "metadata": {
        "id": "3DqDj8Ltq14F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df = pd.read_csv(TEST_CSV)\n",
        "test_df.head()"
      ],
      "metadata": {
        "id": "U4XMtP6krO8O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Train set: ', len(train_df))\n",
        "print('Test set: ', len(test_df))"
      ],
      "metadata": {
        "id": "XsBMHEgwrrad"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check for completeness"
      ],
      "metadata": {
        "id": "ji84mdDFr1l5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Train null counts: \")\n",
        "print(train_df.isnull().sum())\n",
        "print(\"Test null counts: \")\n",
        "print(test_df.isnull().sum())"
      ],
      "metadata": {
        "id": "qIpHDJwVr0eC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check for file existence"
      ],
      "metadata": {
        "id": "-zqfaSX9tIpr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def check_file_existence(df):\n",
        "  missing = []\n",
        "  for fname in df['id']:\n",
        "    if not os.path.isfile(os.path.join(DATA_DIR, fname)):\n",
        "      missing.append(fname)\n",
        "  return missing\n",
        "train_missing = check_file_existence(train_df)\n",
        "test_missing = check_file_existence(test_df)\n",
        "\n",
        "print(f'Missing train: {len(train_missing)}/{len(train_df)}')\n",
        "print(f'Missing test: {len(test_missing)}/{len(test_df)}')"
      ],
      "metadata": {
        "id": "8MHvrmsItClc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "MERGING FULL_FILE PATH"
      ],
      "metadata": {
        "id": "2w6Nx14BellP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df['id'] = train_df['id'].apply(lambda x: os.path.join(DATA_DIR, x))\n",
        "test_df['id'] = test_df['id'].apply(lambda x: os.path.join(DATA_DIR, x))"
      ],
      "metadata": {
        "id": "aBePli8RepZ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df['pair_id'] = train_df.index //2\n",
        "train_df.head()"
      ],
      "metadata": {
        "id": "cxcpM2crRufN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Removing duplicate\n"
      ],
      "metadata": {
        "id": "lIoyEoi-X8AJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Class balance\n",
        "label_counts = train_df[\"label\"].value_counts()\n",
        "plt.figure(figsize=(10, 5))\n",
        "sns.barplot(x=label_counts.index, y=label_counts.values)\n",
        "plt.title(\"Class Distribution\")\n",
        "plt.xlabel(\"Label\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3oCJD2jCcYme"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pair_violations = sum(train_df['label'].diff()[1::2]!= -1) # think of it as if there are 2 of the same labels next to each other it would be 0\n",
        "print(f'Pairing violations: {pair_violations}/{len(train_df)//2}')"
      ],
      "metadata": {
        "id": "BAVqsppahkkG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pair completeness check\n",
        "pair_sizes = train_df.groupby(\"pair_id\")[\"id\"].count().value_counts()\n",
        "print(\"\\nPair size distribution:\")\n",
        "print(pair_sizes)"
      ],
      "metadata": {
        "id": "q5r6m0h_j4hE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "--> K fold cross validation and Binary Cross-Entropy"
      ],
      "metadata": {
        "id": "Uf24aOXEmfVM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "OLg_dMqJX3n1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze_image_metadata(train_df, sample_size=10000):\n",
        "    print(\"=== Image Metadata Analysis ===\")\n",
        "\n",
        "    # Sampling\n",
        "    sample = train_df.sample(sample_size, random_state=42)\n",
        "    metadata = []\n",
        "\n",
        "    for _, row in tqdm(sample.iterrows(), total=sample_size, desc=\"Processing images\"):\n",
        "        img_path = row['id']\n",
        "        try:\n",
        "            with Image.open(img_path) as img:\n",
        "                width, height = img.size\n",
        "                mode = img.mode\n",
        "                format_ = img.format\n",
        "        except:\n",
        "            width, height, mode, format_ = (None,)*4\n",
        "\n",
        "        metadata.append({\n",
        "            \"width\": width,\n",
        "            \"height\": height,\n",
        "            \"channels\": len(mode) if mode else None,\n",
        "            \"format\": format_\n",
        "        })\n",
        "\n",
        "    meta_df = pd.DataFrame(metadata)\n",
        "\n",
        "    # Dimension analysis\n",
        "    print(\"\\n=== Dimension Statistics ===\")\n",
        "    print(f\"Average dimensions: {meta_df['width'].mean():.1f}x{meta_df['height'].mean():.1f}\")\n",
        "    print(\"Dimension distribution:\")\n",
        "    print(meta_df[['width', 'height']].describe())\n",
        "\n",
        "    # Format distribution\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    meta_df['format'].value_counts().plot(kind='bar')\n",
        "    plt.title(\"Image Format Distribution\")\n",
        "    plt.show()\n",
        "\n",
        "    # Channel analysis\n",
        "    channel_dist = meta_df['channels'].value_counts()\n",
        "    print(\"\\nChannel distribution:\")\n",
        "    print(channel_dist)\n",
        "\n",
        "    return meta_df\n",
        "\n",
        "meta_df = analyze_image_metadata(train_df,len(train_df))"
      ],
      "metadata": {
        "id": "QJRLrAaGX2yk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_image_samples(train_df, n_samples=5):\n",
        "    print(\"=== Visual Pattern Analysis ===\")\n",
        "\n",
        "    def plot_comparison(label, title):\n",
        "        plt.figure(figsize=(15, 3))\n",
        "        samples = train_df[train_df['label'] == label].sample(n_samples, random_state=42)\n",
        "        for i, (_, row) in enumerate(samples.iterrows()):\n",
        "            img_path = row['id']\n",
        "            try:\n",
        "                img = Image.open(img_path)\n",
        "                plt.subplot(1, n_samples, i+1)\n",
        "                plt.imshow(img)\n",
        "                plt.title(f\"Label {label}\\n{img.size[0]}x{img.size[1]}\")\n",
        "                plt.axis('off')\n",
        "            except:\n",
        "                plt.title(\"Failed to load\")\n",
        "        plt.suptitle(title)\n",
        "        plt.show()\n",
        "\n",
        "    # Compare AI vs Human\n",
        "    plot_comparison(1, \"AI-Generated Samples\")\n",
        "    plot_comparison(0, \"Human-Created Samples\")\n",
        "\n",
        "visualize_image_samples(train_df,10)"
      ],
      "metadata": {
        "id": "qJPc7qo9lti8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_gray_scale_image_samples(train_df, n_samples=5):\n",
        "    print(\"=== Visual Pattern Analysis ===\")\n",
        "\n",
        "    def load_and_convert_to_gray(img_path):\n",
        "        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)  # Load as grayscale\n",
        "        return img\n",
        "\n",
        "    def plot_comparison(label, title):\n",
        "        plt.figure(figsize=(15, 3))\n",
        "        samples = train_df[train_df['label'] == label].sample(n_samples, random_state=42)\n",
        "        for i, (_, row) in enumerate(samples.iterrows()):\n",
        "            img_path = row['id']\n",
        "            try:\n",
        "                img = load_and_convert_to_gray(img_path)\n",
        "                plt.subplot(1, n_samples, i + 1)\n",
        "                plt.imshow(img, cmap='gray')  # Ensure grayscale display\n",
        "                plt.title(f\"Label {label}\\n{img.shape[1]}x{img.shape[0]}\")\n",
        "                plt.axis('off')\n",
        "            except Exception as e:\n",
        "                print(f\"Error loading image {img_path}: {e}\")\n",
        "                plt.title(\"Failed to load\")\n",
        "        plt.suptitle(title)\n",
        "        plt.show()\n",
        "\n",
        "    # Compare AI vs Human\n",
        "    plot_comparison(1, \"AI-Generated Samples\")\n",
        "    plot_comparison(0, \"Human-Created Samples\")\n",
        "\n",
        "# visualize_gray_scale_image_samples(train_df, 10)"
      ],
      "metadata": {
        "id": "Aff0I-w8TLgJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_pixel_intensity_side_by_side(img1_path,img2_path,title1 = \"AI-Generated Samples\", title2 = \"Human-Created Samples\"):\n",
        "  img1 = cv2.imread(img1_path,cv2.IMREAD_GRAYSCALE)\n",
        "  img2 = cv2.imread(img2_path,cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "  fig, axes = plt.subplots(2, 2, figsize=(12, 10))  # 1 row, 2 columns\n",
        "  # Display Images\n",
        "  axes[0, 0].imshow(img1, cmap='gray')\n",
        "  axes[0, 0].set_title(title1)\n",
        "  axes[0, 0].axis('off')\n",
        "\n",
        "  axes[0, 1].imshow(img2, cmap='gray')\n",
        "  axes[0, 1].set_title(title2)\n",
        "  axes[0, 1].axis('off')\n",
        "\n",
        "  axes[1,0].hist(img1.ravel(), bins=256, color=\"gray\", alpha=0.7)\n",
        "  axes[1,0].set_xlabel(\"Pixel Intensity\")\n",
        "  axes[1,0].set_ylabel(\"Count\")\n",
        "  axes[1,0].set_title(f\"{title1} - Pixel Intensity\")\n",
        "\n",
        "  axes[1,1].hist(img2.ravel(), bins=256, color=\"gray\", alpha=0.7)\n",
        "  axes[1,1].set_xlabel(\"Pixel Intensity\")\n",
        "  axes[1,1].set_ylabel(\"Count\")\n",
        "  axes[1,1].set_title(f\"{title2} - Pixel Intensity\")\n",
        "\n",
        "  plt.tight_layout()\n",
        "  plt.show()\n",
        "\n",
        "sample_ai = train_df[train_df['label'] == 1]['id'].sample(1, random_state=42).values[0]\n",
        "sample_human = train_df[train_df['label'] == 0]['id'].sample(1, random_state=42).values[0]\n",
        "\n",
        "plot_pixel_intensity_side_by_side(sample_ai,sample_human)\n"
      ],
      "metadata": {
        "id": "zzSCxTM1Xxco"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import AdamW, Adam\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torchvision.transforms as T\n",
        "from torchvision.transforms import InterpolationMode\n",
        "import torchvision.models as models"
      ],
      "metadata": {
        "id": "6ActhMd2g-WP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IMG_SIZE = (244,244)"
      ],
      "metadata": {
        "id": "8E772LXoiUxr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_transform = T.Compose([\n",
        "    T.Resize(IMG_SIZE, interpolation=InterpolationMode.BICUBIC),\n",
        "    T.RandomResizedCrop(IMG_SIZE),\n",
        "    T.RandomHorizontalFlip(),\n",
        "    T.RandomVerticalFlip(),\n",
        "    T.RandomRotation(20),\n",
        "    T.GaussianBlur(kernel_size=(7, 13), sigma=(0.1, 1.0)),\n",
        "    T.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])"
      ],
      "metadata": {
        "id": "v9znav1YgyCn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_transforms = T.Compose([\n",
        "    T.Resize(IMG_SIZE, interpolation=InterpolationMode.BICUBIC),\n",
        "    T.CenterCrop(IMG_SIZE),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])"
      ],
      "metadata": {
        "id": "MtxqP8XnkVUE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.to_csv(DATA_DIR + '/pre-train.csv', index=False)\n",
        "test_df.to_csv(DATA_DIR + '/pre-test.csv', index=False)"
      ],
      "metadata": {
        "id": "ZQoTwsSnWCdL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Fr9AVZOxWVAv"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}